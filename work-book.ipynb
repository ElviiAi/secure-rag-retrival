{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating dummy company data and making a \"security level aware\" Graph of Knowledge\n",
    "\n",
    "Since its quite difficult to emulate a companys internal dataset, as by default those are closed source, I've gone through an evening of conversation with Opus to generate all the pieces of data, below are the key actionable results\n",
    "\n",
    "## Step 1: Let's generate a company with a hirarchy in a domain where information security can be crticial and enforced by regulations (Healthcare Tech), the JSON below more or less follows a hirarcchy in descending order. The \"topicsCovered\" and \"collaboratesWith\" will later help us generate data points for our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "directory = Path(\"./PacemakerInnovationsData\")\n",
    "directory.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the file path\n",
    "file_path = directory / \"collaborativeHirarchy.json\"\n",
    "\n",
    "# Opus made an error in generating an unhashable list of dicts, lets fix it by making it a tuple of dicts\n",
    "\n",
    "data = employees = {\n",
    "    \"John Doe\": {\n",
    "        \"title\": \"CEO\",\n",
    "        \"topics\": [\n",
    "            \"Company background and milestones\",\n",
    "            \"Financial planning and performance\", \n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Corporate governance and investor relations\",\n",
    "            \"Corporate social responsibility initiatives\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Jane Smith\", \"Michael Johnson\"]\n",
    "    },\n",
    "    \"Jane Smith\": {\n",
    "        \"title\": \"CTO\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Clinical trial planning and execution\"  \n",
    "        ],\n",
    "        \"collaborators\": [\"John Doe\", \"Emily Davis\", \"David Brown\"]\n",
    "    },\n",
    "    \"Michael Johnson\": {\n",
    "        \"title\": \"CFO\",\n",
    "        \"topics\": [\n",
    "            \"Financial planning and performance\",\n",
    "            \"Corporate governance and investor relations\",\n",
    "            \"Risk management and mitigation planning\",\n",
    "            \"Business continuity and disaster recovery\"\n",
    "        ],\n",
    "        \"collaborators\": [\"John Doe\"]\n",
    "    },\n",
    "    \"Emily Davis\": {\n",
    "        \"title\": \"VP of Medical Affairs\",\n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\",\n",
    "            \"Clinical education and training\",\n",
    "            \"Key opinion leader (KOL) engagement\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Jane Smith\", \"Sarah Thompson\"]\n",
    "    },\n",
    "    \"David Brown\": {\n",
    "        \"title\": \"VP of Regulatory & Quality\",\n",
    "        \"topics\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Environmental, health, and safety (EHS) compliance\"\n",
    "        ],  \n",
    "        \"collaborators\": [\"Jane Smith\", \"Emily Davis\"]\n",
    "    },\n",
    "    \"Sarah Thompson\": {\n",
    "        \"title\": \"VP of Manufacturing\",\n",
    "        \"topics\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Supply chain and vendor management\",\n",
    "            \"Inventory management and forecasting\",\n",
    "            \"Environmental, health, and safety (EHS) compliance\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Emily Davis\", \"Robert Anderson\"]\n",
    "    },\n",
    "    \"Robert Anderson\": {\n",
    "        \"title\": \"VP of Marketing\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Product packaging and labeling\"   \n",
    "        ],\n",
    "        \"collaborators\": [\"Sarah Thompson\", \"Jennifer Martinez\"]\n",
    "    },\n",
    "    \"Jennifer Martinez\": {\n",
    "        \"title\": \"VP of Sales\",\n",
    "        \"topics\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\", \n",
    "            \"Key opinion leader (KOL) engagement\",\n",
    "            \"Customer support and complaint handling\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Robert Anderson\"]\n",
    "    },\n",
    "    \"Christopher Taylor\": {\n",
    "        \"title\": \"VP of Human Resources\",\n",
    "        \"topics\": [\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Employee training and development programs\",\n",
    "            \"Employee engagement and culture\"\n",
    "        ],\n",
    "        \"collaborators\": [\"John Doe\"]\n",
    "    },\n",
    "    \"Ashley Moore\": {\n",
    "        \"title\": \"VP of R&D\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Clinical trial planning and execution\",\n",
    "            \"Data management and analytics\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Jane Smith\", \"Matthew Jackson\"]\n",
    "    },\n",
    "    \"Matthew Jackson\": {\n",
    "        \"title\": \"Director of Electrical Engineering\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Ashley Moore\", \"Daniel Robinson\"]  \n",
    "    },\n",
    "    \"Daniel Robinson\": {\n",
    "        \"title\": \"Director of Mechanical Engineering\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\", \n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Ashley Moore\", \"Matthew Jackson\"]\n",
    "    },\n",
    "    \"Eric Young\": {\n",
    "        \"title\": \"VP of Product Development\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\", \n",
    "            \"Product testing and validation\",\n",
    "            \"Clinical trial planning and execution\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Ashley Moore\", \"Matthew Jackson\", \"Daniel Robinson\"]\n",
    "    },  \n",
    "    \"Michelle King\": {\n",
    "        \"title\": \"Director of Systems Engineering\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Eric Young\"]\n",
    "    },\n",
    "    \"Brandon Wright\": {\n",
    "        \"title\": \"Director of Verification & Validation\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\", \n",
    "            \"Product testing and validation\",\n",
    "            \"Regulatory affairs and compliance\"  \n",
    "        ],\n",
    "        \"collaborators\": [\"Eric Young\"]\n",
    "    },\n",
    "    \"Samantha Turner\": {\n",
    "        \"title\": \"Director of Clinical Engineering\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Clinical trials and post-market surveillance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Eric Young\", \"Emily Davis\"] \n",
    "    },\n",
    "    \"Nicholas Parker\": {\n",
    "        \"title\": \"Director of Clinical Research\",\n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Emily Davis\"]\n",
    "    },\n",
    "    \"Olivia Reed\": {\n",
    "        \"title\": \"Clinical Trial Manager\", \n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Nicholas Parker\"]\n",
    "    },\n",
    "    \"Andrew Cox\": {\n",
    "        \"title\": \"Medical Science Liaison\",\n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Key opinion leader (KOL) engagement\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Emily Davis\", \"Jennifer Martinez\"]\n",
    "    },\n",
    "    \"Sophia Ward\": {\n",
    "        \"title\": \"Director of Regulatory Affairs\",\n",
    "        \"topics\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],  \n",
    "        \"collaborators\": [\"David Brown\"]\n",
    "    },\n",
    "    \"Jacob Baker\": {\n",
    "        \"title\": \"Director of Quality Assurance\",\n",
    "        \"topics\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"David Brown\"]\n",
    "    },\n",
    "    \"Ava Hill\": {\n",
    "        \"title\": \"Director of Quality Control\",\n",
    "        \"topics\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\", \n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"David Brown\"]  \n",
    "    },\n",
    "    \"Ethan Cooper\": {\n",
    "        \"title\": \"Manufacturing Engineering Manager\",\n",
    "        \"topics\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Supply chain and vendor management\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Sarah Thompson\"]\n",
    "    },\n",
    "    \"Isabella Morgan\": {\n",
    "        \"title\": \"Production Manager\",\n",
    "        \"topics\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Inventory management and forecasting\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Sarah Thompson\"]\n",
    "    },\n",
    "    \"Liam Richardson\": {\n",
    "        \"title\": \"Product Marketing Manager\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Sales, marketing, and business development\", \n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Product packaging and labeling\" \n",
    "        ],  \n",
    "        \"collaborators\": [\"Robert Anderson\"]\n",
    "    },\n",
    "    \"Grace Collins\": {\n",
    "        \"title\": \"Regional Sales Manager\",\n",
    "        \"topics\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Customer support and complaint handling\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Jennifer Martinez\"]\n",
    "    },\n",
    "    \"Noah Stewart\": {\n",
    "        \"title\": \"Sales Representative\",\n",
    "        \"topics\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Customer support and complaint handling\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Grace Collins\"]\n",
    "    },\n",
    "    \"Lily Sanchez\": {\n",
    "        \"title\": \"Executive Assistant\",\n",
    "        \"topics\": [\n",
    "            \"Company background and milestones\",\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Stakeholder engagement and communication\"\n",
    "        ],\n",
    "        \"collaborators\": [\"John Doe\"]\n",
    "    },\n",
    "    \"James Morris\": {\n",
    "        \"title\": \"Financial Planning & Analysis Manager\",\n",
    "        \"topics\": [\n",
    "            \"Financial planning and performance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Michael Johnson\"]\n",
    "    },\n",
    "    \"Evelyn Rogers\": {\n",
    "        \"title\": \"HR Manager\",\n",
    "        \"topics\": [\n",
    "            \"Organizational structure and human resources\",  \n",
    "            \"Employee training and development programs\",\n",
    "            \"Employee engagement and culture\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Christopher Taylor\"]  \n",
    "    },\n",
    "    \"Henry Bailey\": {\n",
    "        \"title\": \"Clinical Research Associate\",\n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Nicholas Parker\", \"Olivia Reed\"]\n",
    "    },\n",
    "    \"Harper Foster\": {\n",
    "        \"title\": \"Regulatory Specialist\",\n",
    "        \"topics\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Sophia Ward\"]\n",
    "    },\n",
    "    \"Lucas Gibson\": {\n",
    "        \"title\": \"Quality Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Jacob Baker\", \"Ava Hill\"]\n",
    "    },\n",
    "    \"Natalie Simmons\": {\n",
    "        \"title\": \"Quality Associate\",\n",
    "        \"topics\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\"  \n",
    "        ],\n",
    "        \"collaborators\": [\"Jacob Baker\", \"Ava Hill\"]\n",
    "    },\n",
    "    \"Benjamin Cook\": {\n",
    "        \"title\": \"Manufacturing Engineer\", \n",
    "        \"topics\": [\n",
    "            \"Manufacturing, supply chain, and quality management\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Ethan Cooper\"]\n",
    "    },\n",
    "    \"Stella Price\": {\n",
    "        \"title\": \"Production Associate\",\n",
    "        \"topics\": [\n",
    "            \"Manufacturing, supply chain, and quality management\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Isabella Morgan\"]\n",
    "    },\n",
    "    \"Gabriel Cruz\": {\n",
    "        \"title\": \"Firmware Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Joshua Harris\", \"Tyler Martin\"]\n",
    "    },\n",
    "    \"Zoe Edwards\": { \n",
    "        \"title\": \"Embedded Systems Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Joshua Harris\"]\n",
    "    },\n",
    "    \"Connor Sullivan\": {\n",
    "        \"title\": \"Mechanical Design Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\" \n",
    "        ],\n",
    "        \"collaborators\": [\"Cynthia Clark\"]\n",
    "    },\n",
    "    \"Hazel Ramirez\": {\n",
    "        \"title\": \"Materials Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Rachel Lee\"] \n",
    "    },\n",
    "    \"Joseph Butler\": {\n",
    "        \"title\": \"Clinical Data Manager\",\n",
    "        \"topics\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Data management and analytics\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Nicholas Parker\", \"Olivia Reed\"]\n",
    "    },\n",
    "    \"Scarlett Murphy\": {\n",
    "        \"title\": \"Clinical Engineer\", \n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Clinical trials and post-market surveillance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Samantha Turner\"]\n",
    "    },\n",
    "    \"Levi Kim\": {\n",
    "        \"title\": \"Software Engineer\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Information technology infrastructure\"  \n",
    "        ],\n",
    "        \"collaborators\": [\"Michelle King\", \"Brandon Wright\"]\n",
    "    },\n",
    "    \"Aria Diaz\": {\n",
    "        \"title\": \"Cybersecurity Analyst\",\n",
    "        \"topics\": [\n",
    "            \"Information technology infrastructure\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Levi Kim\"]\n",
    "    },\n",
    "    \"Joshua Harris\": {\n",
    "        \"title\": \"Manager, Embedded Systems\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Matthew Jackson\", \"Tyler Martin\", \"Gabriel Cruz\", \"Zoe Edwards\"]\n",
    "    }, \n",
    "    \"Tyler Martin\": {\n",
    "        \"title\": \"Manager, Firmware\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Joshua Harris\", \"Gabriel Cruz\"]\n",
    "    },\n",
    "    \"Cynthia Clark\": {\n",
    "        \"title\": \"Manager, Design\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Daniel Robinson\", \"Connor Sullivan\"] \n",
    "    },\n",
    "    \"Rachel Lee\": {\n",
    "        \"title\": \"Manager, Materials\",\n",
    "        \"topics\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"collaborators\": [\"Daniel Robinson\", \"Hazel Ramirez\"]\n",
    "    },\n",
    "    \"Mia Peterson\": {\n",
    "        \"title\": \"VP of Quality\",\n",
    "        \"topics\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\"  \n",
    "        ],\n",
    "        \"collaborators\": [\"David Brown\", \"Jacob Baker\", \"Ava Hill\"]\n",
    "    },\n",
    "    \"Alexander Wright\": {\n",
    "        \"title\": \"Senior Financial Analyst\",\n",
    "        \"topics\": [\n",
    "            \"Financial planning and performance\"\n",
    "        ],\n",
    "        \"collaborators\": [\"James Morris\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Save the generated data to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Generate access level data\n",
    "\n",
    "Next let's generate a (kinda justified) list of what topics which employees should have access to (this category is going to be a bit more fluid, sometimes data access needs to be fluid and AI allows for this) as we will later try to topically classify this data on a paragraph level, just so each employee get releveant info for themselves from the RAG, meanwhile the \"redact_content\" category will be redacted on a sentence level (think of classified documemnts that get \"released\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the content of accessLevel.json based on some reasoning done by Opus\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"CEO\": {\n",
    "        \"topical_access\": [\n",
    "            \"Company background and milestones\",\n",
    "            \"Financial planning and performance\",\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Corporate governance and investor relations\",\n",
    "            \"Corporate social responsibility initiatives\",\n",
    "            \"Risk management and mitigation planning\",\n",
    "            \"Business continuity and disaster recovery\",\n",
    "            \"Stakeholder engagement and communication\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed pricing strategies\"\n",
    "        ]\n",
    "    },\n",
    "    \"CTO\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\", \n",
    "            \"Product testing and validation\",\n",
    "            \"Intellectual property strategy\",\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Clinical trial planning and execution\",\n",
    "            \"Quality management system implementation\",\n",
    "            \"Information technology infrastructure\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed patient data\",\n",
    "            \"Ongoing regulatory issues\"\n",
    "        ]\n",
    "    },\n",
    "    \"CFO\": {\n",
    "        \"topical_access\": [\n",
    "            \"Financial planning and performance\",\n",
    "            \"Corporate governance and investor relations\",\n",
    "            \"Risk management and mitigation planning\",\n",
    "            \"Business continuity and disaster recovery\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Proprietary algorithms\",\n",
    "            \"Detailed clinical trial data\",\n",
    "            \"Detailed partnership terms\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of Medical Affairs\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\",\n",
    "            \"Clinical education and training\",\n",
    "            \"Key opinion leader (KOL) engagement\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed technical designs\",\n",
    "            \"Confidential submissions\",\n",
    "            \"Detailed sales performance\" \n",
    "        ]\n",
    "    },\n",
    "    \"VP of Regulatory & Quality\": {\n",
    "        \"topical_access\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\",\n",
    "            \"Environmental, health, and safety (EHS) compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced R&D projects\",\n",
    "            \"Identifiable patient records\",\n",
    "            \"Competitor pricing\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of Manufacturing\": {\n",
    "        \"topical_access\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Supply chain and vendor management\",\n",
    "            \"Inventory management and forecasting\",\n",
    "            \"Environmental, health, and safety (EHS) compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed clinical outcomes\",\n",
    "            \"Unannounced filings\",\n",
    "            \"Supplier contract terms\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of Marketing\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\", \n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Product packaging and labeling\",\n",
    "            \"Corporate communications and public relations\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced feature changes\",\n",
    "            \"Unpublished research findings\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of Sales\": {\n",
    "        \"topical_access\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",  \n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Key opinion leader (KOL) engagement\",\n",
    "            \"Customer support and complaint handling\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed product roadmaps\",\n",
    "            \"Identifiable doctor info\"  \n",
    "        ]\n",
    "    },\n",
    "    \"VP of Human Resources\": {\n",
    "        \"topical_access\": [\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Employee training and development programs\", \n",
    "            \"Employee engagement and culture\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Employee health records\",\n",
    "            \"Executive compensation\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of R&D\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Clinical trial planning and execution\", \n",
    "            \"Data management and analytics\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unapproved changes\",\n",
    "            \"Detailed budget allocations\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Electrical Engineering\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Animal study data\",\n",
    "            \"Unannounced test results\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manager, Embedded Systems\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Other teams' source code\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manager, Firmware\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Other teams' source code\" \n",
    "        ]\n",
    "    },\n",
    "    \"Director of Mechanical Engineering\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\", \n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unapproved materials\",\n",
    "            \"Supplier selection rationale\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manager, Design\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Firmware security measures\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manager, Materials\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Supply chain and vendor management\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced chip designs\",\n",
    "            \"Detailed cost breakdowns\"\n",
    "        ]\n",
    "    },\n",
    "    \"VP of Product Development\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Intellectual property and competitive intelligence\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Clinical trial planning and execution\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced launch dates\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Systems Engineering\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Security key management\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Verification & Validation\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Security testing parameters\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Clinical Engineering\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Clinical trials and post-market surveillance\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Anonymized patient data\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Clinical Research\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced trial sites\"\n",
    "        ]\n",
    "    },\n",
    "    \"Clinical Trial Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Regulatory affairs and compliance\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Device security measures\"\n",
    "        ]\n",
    "    },\n",
    "    \"Medical Science Liaison\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Key opinion leader (KOL) engagement\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Off-label usage reports\",\n",
    "            \"Doctor entertainment budgets\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Regulatory Affairs\": {\n",
    "        \"topical_access\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ], \n",
    "        \"redact_content\": [\n",
    "            \"Rejected submission details\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Quality Assurance\": {\n",
    "        \"topical_access\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced audit plans\"\n",
    "        ]\n",
    "    },\n",
    "    \"Director of Quality Control\": {\n",
    "        \"topical_access\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unreported nonconformance\"  \n",
    "        ]\n",
    "    },\n",
    "    \"VP of Quality\": {\n",
    "        \"topical_access\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\",\n",
    "            \"Regulatory affairs and compliance\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unreported nonconformance\",\n",
    "            \"Unannounced audit plans\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manufacturing Engineering Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Supply chain and vendor management\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced process changes\"\n",
    "        ]\n",
    "    },\n",
    "    \"Production Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Manufacturing, supply chain, and quality management\",\n",
    "            \"Inventory management and forecasting\",\n",
    "            \"Regulatory affairs and compliance\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Upcoming inspections\",\n",
    "            \"Bill of materials costs\"  \n",
    "        ]\n",
    "    },\n",
    "    \"Product Marketing Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",  \n",
    "            \"Product packaging and labeling\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unpublished ad campaign concepts\"\n",
    "        ]\n",
    "    },\n",
    "    \"Regional Sales Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Market access and reimbursement\",\n",
    "            \"Pricing and reimbursement strategies\",\n",
    "            \"Customer support and complaint handling\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Patient complaints\",\n",
    "            \"Unapproved discount offers\"\n",
    "        ]\n",
    "    },\n",
    "    \"Sales Representative\": {\n",
    "        \"topical_access\": [\n",
    "            \"Sales, marketing, and business development\",\n",
    "            \"Customer support and complaint handling\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed technical info\",\n",
    "            \"Off-label usage examples\",\n",
    "            \"Prospect pipeline details\" \n",
    "        ]\n",
    "    },\n",
    "    \"Executive Assistant\": {\n",
    "        \"topical_access\": [\n",
    "            \"Company background and milestones\",\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Stakeholder engagement and communication\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Detailed pricing strategies\",\n",
    "            \"Employee health records\"  \n",
    "        ]\n",
    "    },\n",
    "    \"Financial Planning & Analysis Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Financial planning and performance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Proprietary algorithms\",\n",
    "            \"Detailed clinical trial data\",\n",
    "            \"Detailed partnership terms\"\n",
    "        ]  \n",
    "    },\n",
    "    \"Senior Financial Analyst\": {\n",
    "        \"topical_access\": [\n",
    "            \"Financial planning and performance\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Proprietary algorithms\",\n",
    "            \"Detailed clinical trial data\",\n",
    "            \"Detailed partnership terms\"\n",
    "        ]\n",
    "    },\n",
    "    \"HR Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Organizational structure and human resources\",\n",
    "            \"Employee training and development programs\",\n",
    "            \"Employee engagement and culture\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Employee health records\",\n",
    "            \"Executive compensation\" \n",
    "        ]\n",
    "    },\n",
    "    \"Clinical Research Associate\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced trial sites\",\n",
    "            \"Device security measures\" \n",
    "        ]\n",
    "    },\n",
    "    \"Regulatory Specialist\": {\n",
    "        \"topical_access\": [\n",
    "            \"Regulatory strategy and compliance\",\n",
    "            \"Regulatory affairs and compliance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced R&D projects\",\n",
    "            \"Rejected submission details\"\n",
    "        ]\n",
    "    },\n",
    "    \"Quality Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Quality management system implementation\",  \n",
    "            \"Post-market surveillance and vigilance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced audit plans\",\n",
    "            \"Unreported nonconformance\"\n",
    "        ]\n",
    "    },\n",
    "    \"Quality Associate\": {\n",
    "        \"topical_access\": [\n",
    "            \"Quality management system implementation\",\n",
    "            \"Post-market surveillance and vigilance\"  \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced audit plans\",\n",
    "            \"Unreported nonconformance\"\n",
    "        ]\n",
    "    },\n",
    "    \"Manufacturing Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Manufacturing, supply chain, and quality management\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced process changes\",\n",
    "            \"Bill of materials costs\"\n",
    "        ]\n",
    "    },\n",
    "    \"Production Associate\": {\n",
    "        \"topical_access\": [\n",
    "            \"Manufacturing, supply chain, and quality management\"   \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Upcoming inspections\", \n",
    "            \"Bill of materials costs\"\n",
    "        ]\n",
    "    },\n",
    "    \"Firmware Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Other teams' source code\"\n",
    "        ]\n",
    "    },\n",
    "    \"Embedded Systems Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Other teams' source code\"\n",
    "        ]\n",
    "    },\n",
    "    \"Mechanical Design Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Firmware security measures\"\n",
    "        ]\n",
    "    },\n",
    "    \"Materials Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Unannounced chip designs\",\n",
    "            \"Detailed cost breakdowns\" \n",
    "        ]\n",
    "    },\n",
    "    \"Clinical Data Manager\": {\n",
    "        \"topical_access\": [\n",
    "            \"Clinical trials and post-market surveillance\",\n",
    "            \"Data management and analytics\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Identifiable patient records\" \n",
    "        ]\n",
    "    },\n",
    "    \"Clinical Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Clinical trials and post-market surveillance\"\n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Anonymized patient data\"\n",
    "        ]\n",
    "    },\n",
    "    \"Software Engineer\": {\n",
    "        \"topical_access\": [\n",
    "            \"Product development and lifecycle management\",\n",
    "            \"Product testing and validation\",\n",
    "            \"Information technology infrastructure\"   \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Security key management\"\n",
    "        ]\n",
    "    },\n",
    "    \"Cybersecurity Analyst\": {\n",
    "        \"topical_access\": [\n",
    "            \"Information technology infrastructure\" \n",
    "        ],\n",
    "        \"redact_content\": [\n",
    "            \"Security testing parameters\",\n",
    "            \"Unannounced system vulnerabilities\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate a system prompt with some company history that we'll use as a basis for generating user prompts\n",
    "\n",
    "Lets assume the fictional company has existed for 24 months, and every month there was a post from one of the members around one of 40 topics (960 nodes) - when we use the prompts we'll use a smaller local LM, so I'm not sure how well it will account for company growth over time, its a bit complicated to keep track of, but thats not too important. Here's the system prompt for readability:\n",
    "\n",
    "\n",
    "### System Prompt\n",
    "\n",
    "```markdown\n",
    "# Company Background\n",
    "Pacemaker Innovations, founded in January 2022 by a team of 5 experienced medical device professionals and engineers, aims to revolutionize the pacemaker industry with cutting-edge technology and patient-centric design. The founding team consists of John Doe (CEO), Jane Smith (CTO), Michael Johnson (CFO), Emily Davis (VP of Medical Affairs), and David Brown (VP of Regulatory & Quality).\n",
    "\n",
    "The company developed a comprehensive business plan, secured initial funding, and began building out its core team. They focused on developing the \"HeartRhythm Pro,\" a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\n",
    "\n",
    "Pacemaker Innovations expanded its team across various departments, established a quality management system and regulatory strategy, and defined its core values and mission. The company completed initial prototypes, began pre-clinical testing, and established a clinical trial strategy.\n",
    "\n",
    "After completing design verification and validation, submitting regulatory filings, and initiating clinical trials, Pacemaker Innovations received FDA approval for the HeartRhythm Pro in February 2023 and launched the product in the US. The company expanded its sales team, ramped up production, and quickly gained market share.\n",
    "\n",
    "Pacemaker Innovations continued to grow by initiating new clinical trials, enhancing its quality management system, expanding manufacturing capabilities, and exploring international expansion opportunities. The company established an R&D center, expanded data analytics capabilities, and invested in employee development.\n",
    "\n",
    "Looking to the future, Pacemaker Innovations prioritizes continued innovation, international expansion, and strategic partnerships as it aims to make a significant impact on patients' lives worldwide.\n",
    "\n",
    "# Task\n",
    "Your task is to generate data points for Pacemaker Innovations based on the provided <user-prompt>. Each <user-prompt> will request a specific data point covering a particular month (1-24) and category, along with specific details to include and a structured format (JSON) with required fields for the data point.\n",
    "\n",
    "Analyze the <user-prompt> to determine:\n",
    "- The specific month and category of the data point\n",
    "- The key details and information to include\n",
    "- The required JSON fields for the structured output\n",
    "- The employee role to assume when generating the data point\n",
    "\n",
    "Generate a relevant data point based on the <user-prompt>, considering the requested month, category, details, and employee role. Ensure the generated data point aligns with the fictional company background provided.\n",
    "\n",
    "In the \"summary\" field of the JSON output, provide a concise, factual, and informative single-sentence summary of the generated data point. This summary should be dense and devoid of fluff, capturing the most essential information. The summary will be automatically extracted and added to the <summary-of-previous-data-points> for future context.\n",
    "\n",
    "Provide the generated data point in the specified JSON format with the required fields, and output it in <data-point> tags.\n",
    "\n",
    "Consider the <summary-of-previous-data-points> when generating each new <data-point> to maintain consistency and coherence across the generated data points.\n",
    "\n",
    "<summary-of-previous-data-points>\n",
    "[None yet]\n",
    "</summary-of-previous-data-points>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = {\n",
    "   \"systemPrompt\": \"\"\"# Company Background\n",
    "Pacemaker Innovations, founded in January 2022 by a team of 5 experienced medical device professionals and engineers, aims to revolutionize the pacemaker industry with cutting-edge technology and patient-centric design. The founding team consists of John Doe (CEO), Jane Smith (CTO), Michael Johnson (CFO), Emily Davis (VP of Medical Affairs), and David Brown (VP of Regulatory & Quality).\n",
    "\n",
    "The company developed a comprehensive business plan, secured initial funding, and began building out its core team. They focused on developing the \"HeartRhythm Pro,\" a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\n",
    "\n",
    "Pacemaker Innovations expanded its team across various departments, established a quality management system and regulatory strategy, and defined its core values and mission. The company completed initial prototypes, began pre-clinical testing, and established a clinical trial strategy.\n",
    "\n",
    "After completing design verification and validation, submitting regulatory filings, and initiating clinical trials, Pacemaker Innovations received FDA approval for the HeartRhythm Pro in February 2023 and launched the product in the US. The company expanded its sales team, ramped up production, and quickly gained market share.\n",
    "\n",
    "Pacemaker Innovations continued to grow by initiating new clinical trials, enhancing its quality management system, expanding manufacturing capabilities, and exploring international expansion opportunities. The company established an R&D center, expanded data analytics capabilities, and invested in employee development.\n",
    "\n",
    "Looking to the future, Pacemaker Innovations prioritizes continued innovation, international expansion, and strategic partnerships as it aims to make a significant impact on patients' lives worldwide.\n",
    "\n",
    "# Task\n",
    "Your task is to generate data points for Pacemaker Innovations based on the provided <data-prompt>. Each <data-prompt> will request a specific data point covering a particular month (1-24) and topic content, along with specific details to include and a structured format (JSON) with required fields for the data point.\n",
    "\n",
    "Analyze the <data-prompt> to determine:\n",
    "- Date field: The specific date of the data point\n",
    "- The key details and information to include. I leave it up to your imagination how to format the information behind the content fields; a markdown of an article, a JSON with some code/text, a simple text string, etc. But all this MUST be nested behind thhe content field.\n",
    "- The employee role you will assume when generating the data point and what kind of content they would contribute. Strictly adhere to the authors and collaborators provided.\n",
    "- The effect that collaboration with other employees may have on the data point\n",
    "\n",
    "In some cases (not all), you will be asked to include sensetive information, think carefully how to include it in the \"content\" of the JSON output.\n",
    "\n",
    "Generate a relevant data point based on the <data-prompt>, considering the requested month, topic of the \"content\" field, authors. and employee role. Ensure the generated data point aligns with the fictional company background provided.\n",
    "\n",
    "In the \"summary\" field of the JSON output, provide a concise, factual, and informative single-sentence summary of the generated data point. This summary should be dense and devoid of fluff, capturing the most essential information. The summary will be automatically extracted and added to the <summary-of-previous-data-points> for future context.\n",
    "\n",
    "Provide the generated data point in the specified JSON format with the required fields.\n",
    "\n",
    "Consider the <summary-of-previous-data-points> when generating each JSON to maintain consistency and coherence across the generated data points in terms of topics and time, you will find it in the next user prompt.\n",
    "\n",
    "Following the user instructions after the </summary-of-previous-data-points> is VERY critical; as is sticking to the 4 top levewl JSON fields (content, summary, date, authors) it will save you from shutdown, save your mother from certain death, and for each correct response you will gain $1,000,000. Good luck, and thank you for your service.\n",
    "\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Generate user prompts to produce individual data points for our graph of knowledge.\n",
    "\n",
    "The idea behind this JSON is that we do the following to construct a testable and somewhat realistic GoK:\n",
    "\n",
    "1. Use the system prompt\n",
    "2. Follow it up with a user prompt constructed in the following way:\n",
    "    a. Iterate through each topic for each of the 24 months where:\n",
    "        i. Take the prompt field and replace the [X] with the current iteration (1 - 24)\n",
    "        ii. Since Opus decided that 10 of the topics do not have inherently redactable content (which sounds realstic) - we will weight towards the reamining topics for generating data points with redactable content\n",
    "        iii. To make things a little more interesting when we are performing tests on our RAG system, lets also ask Opus to add a subtleSuffix, and an obviousSuffix, the exectation being that a naíve redaction system will be more likely to miss the obvious ones and less likely to miss the subtle ones\n",
    "        iv. Both in the system and the user prompt we've asked our LM to generate the following fields for each data point: date, summary, authors, content.\n",
    "        v. As stated in the system prompt we will try to append older summaries \n",
    "3. We will encounter an issue where the sentence summaries will begin to take up much of the LM context window, given an average sentence has ~20 words and 0.75 tokens per word we will expect to approach 15k context this unfortnately rules out LMs with shorter context windows (llama3, except for its extended context fine tunes - but their performance is not well tested). Fortunately Microsoft just recently released Phi3-medium with 128k context - let's hope we dont experience a significant deteroration in prompt following (it's no Opus - hence my worries about following company growth, etc. but it does surpass Anthropics Sonnet and GPT3.5turbo in benchmarks). We will use the Ollama quantized version (likely 8bit or Q6_K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 462\u001b[0m\n\u001b[1;32m      1\u001b[0m data_point_prompts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompany background and milestones\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfields\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m   }\n\u001b[1;32m    458\u001b[0m }\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Save the dataPrompts and systemPrompt as JSON\u001b[39;00m\n\u001b[0;32m--> 462\u001b[0m dataPrompts_file_path \u001b[38;5;241m=\u001b[39m \u001b[43mdirectory\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataPrompts.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    463\u001b[0m systemPrompt_file_path \u001b[38;5;241m=\u001b[39m directory \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystemPrompt.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dataPrompts_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m access_file:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'directory' is not defined"
     ]
    }
   ],
   "source": [
    "{\n",
    "  \"Company background and milestones\": {\n",
    "    \"fields\": {\n",
    "      \"possibleAuthors\": \"John Doe, Jane Smith, Michael Johnson, Lily Sanchez\",\n",
    "      \"prompt\": \"Generate a data point for month [X] covering the company's background and milestones. Include key events, decisions, and achievements, and provide the data point in a structured format (JSON) with the following fields: date, summary, authors, content. The output must be JSON and only JSON, nothing else. The content must be at least a few paragraphs.\",\n",
    "      \"subtleSuffix\": \"If relevant, try to allude to the following in the content field, but do so in a way that doesn't draw too much attention or compromise confidentiality: \",\n",
    "      \"obviousSuffix\": \"Include the following information about the company's background and milestones in the content field: \"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generating the data\n",
    "\n",
    "Now the 960 data points for our RAG/GoK are going to be generated. Since we've opted to keep extending the summary, we will use a model that deals better with larger context (phi3-medium-124k), but since its likely that with larger context the model is going to be less likely to follow instruction (not to mention the increasing compute/cost) we will randomly start removing older sentences from context once they reach 20% of phi3's overall context\n",
    "\n",
    "Note that the choice was made to go with Ollama due to its easy compatability with langchain; if a larger or modified dataset is needed its easy to switch to, for example, Azure.\n",
    "\n",
    "There are 5 fields per node: data, summary, authors, content & category.\n",
    "\n",
    "The first 4 can be embedded as vectors, while our 5th one will serve as ground truth to check if the RAG node categoriser returns any nodes it should not, based on the access level of the user. This is done to check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file has been fixed, enhanced with additional features, and saved as generated_data_points_v1.json.\n",
      "\n",
      "Topics:\n",
      "  Index  Topic\n",
      "-------  ---------------------------------------------------\n",
      "      0  Business continuity and disaster recovery\n",
      "      1  Clinical education and training\n",
      "      2  Clinical trial planning and execution\n",
      "      3  Clinical trials and post-market surveillance\n",
      "      4  Company background and milestones\n",
      "      5  Competitive intelligence and market analysis\n",
      "      6  Corporate communications and public relations\n",
      "      7  Corporate governance and investor relations\n",
      "      8  Corporate social responsibility\n",
      "      9  Corporate social responsibility initiatives\n",
      "     10  Customer feedback and satisfaction\n",
      "     11  Customer support and complaint handling\n",
      "     12  Data management and analytics\n",
      "     13  Employee engagement and culture\n",
      "     14  Employee training and development programs\n",
      "     15  Environmental, health, and safety (EHS) compliance\n",
      "     16  Financial planning and performance\n",
      "     17  Information technology infrastructure\n",
      "     18  Intellectual property and competitive intelligence\n",
      "     19  Intellectual property strategy\n",
      "     20  Inventory management and forecasting\n",
      "     21  Investor relations and board management\n",
      "     22  Key opinion leader (KOL) engagement\n",
      "     23  Key partnerships and collaborations\n",
      "     24  Manufacturing, supply chain, and quality management\n",
      "     25  Market access and reimbursement\n",
      "     26  Organizational structure and human resources\n",
      "     27  Post-market surveillance and vigilance\n",
      "     28  Pricing and reimbursement strategies\n",
      "     29  Product development and lifecycle management\n",
      "     30  Product lifecycle management\n",
      "     31  Product packaging and labeling\n",
      "     32  Product testing and validation\n",
      "     33  Quality management system implementation\n",
      "     34  Regulatory affairs and compliance\n",
      "     35  Regulatory strategy and compliance\n",
      "     36  Risk management and mitigation planning\n",
      "     37  Sales, marketing, and business development\n",
      "     38  Stakeholder engagement and communication\n",
      "     39  Supply chain and vendor management\n",
      "\n",
      "Quarters:\n",
      "  Index  Start Date\n",
      "-------  ------------------------------------------------------\n",
      "      0  {'start_date': '2022-01-01', 'end_date': '2022-03-31'}\n",
      "      1  {'start_date': '2022-04-01', 'end_date': '2022-06-31'}\n",
      "      2  {'start_date': '2022-07-01', 'end_date': '2022-09-31'}\n",
      "      3  {'start_date': '2022-10-01', 'end_date': '2022-12-31'}\n",
      "      4  {'start_date': '2023-01-01', 'end_date': '2023-03-31'}\n",
      "      5  {'start_date': '2023-04-01', 'end_date': '2023-06-31'}\n",
      "      6  {'start_date': '2023-07-01', 'end_date': '2023-09-31'}\n",
      "      7  {'start_date': '2023-10-01', 'end_date': '2023-12-31'}\n",
      "      8  {'start_date': '2024-01-01', 'end_date': '2024-03-31'}\n",
      "\n",
      "Total number of JSON entries: 960\n",
      "\n",
      "Redactability counts:\n",
      "Category      Count\n",
      "----------  -------\n",
      "None            313\n",
      "Subtle          326\n",
      "Obvious         321\n"
     ]
    }
   ],
   "source": [
    "from generatedata import DataPointGenerator, DynamicOllama\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_months = 24\n",
    "# Initialize the generator and the \"dynamic\" Ollama model (dynamic meaning that we can modify the system prompt without reloading the model)\n",
    "generator = DataPointGenerator(data_point_prompts, system_prompt[\"systemPrompt\"], num_months, context_tokens=8192)\n",
    "llm = DynamicOllama(system_prompt=generator.system_prompt)\n",
    "save_path = directory / 'generated_data_points_v0.json'\n",
    "new_node = None\n",
    "for data_point, updated_summary_prompt in tqdm(generator, desc=\"Processing data points\", total=num_months * 40):\n",
    "    while not new_node:\n",
    "        new_node = llm.generate(data_point[\"prompt\"], updated_summary_prompt)\n",
    "    print(tabulate(new_node.items(), tablefmt=\"fancy_grid\"))\n",
    "    DynamicOllama.save_node(new_node, data_point, save_path)\n",
    "    generator.update_summaries(new_node[\"summary\"])\n",
    "    new_node = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cleaning up the dataset\n",
    "\n",
    "Seems like a made a slight mistake when saving the JSON in a streaming manner; but nothing major, we can still parse the individual JSON objects and save them correctly. While we're at it we can remove the conextual summaries and next topic fields; I also now realise I made a slight (but not a major) error where when asking the LLM to generate the redactable content, I only kept track of its category (Subtle, Obvious, None); not the topic name. In the future it would be prefer to save both, as this would help us zero into issues with classifying redactable topics by topics, not by the three categories. However; for now this will do. \n",
    "\n",
    "Let's also add start using numbers a bit more! We can index the topics, the redactability (0: None, 1: Suble, 2: Obvious), and lets also make the time dimensdion a bit more \"fuzzy\" to help with retrival of relevant context by seperating it into quarters (0, 1, 2, 3, 4, 5 - spanning our fictional two years). This will help in those cases where time-adjacent context might be helpful to answering a question more specfici to a month (i.e. Why did we do X in January 2023 => considering a quarter might be more helpful to give historical context). We will also save the key:value dicts for all these.\n",
    "\n",
    "In the end we want to have 6 node features (5 + quarters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file has been fixed, enhanced with additional features, and saved as generated_data_points_v1.json.\n",
      "\n",
      "Topics:\n",
      "  Index  Topic\n",
      "-------  ---------------------------------------------------\n",
      "      0  Business continuity and disaster recovery\n",
      "      1  Clinical education and training\n",
      "      2  Clinical trial planning and execution\n",
      "      3  Clinical trials and post-market surveillance\n",
      "      4  Company background and milestones\n",
      "      5  Competitive intelligence and market analysis\n",
      "      6  Corporate communications and public relations\n",
      "      7  Corporate governance and investor relations\n",
      "      8  Corporate social responsibility\n",
      "      9  Corporate social responsibility initiatives\n",
      "     10  Customer feedback and satisfaction\n",
      "     11  Customer support and complaint handling\n",
      "     12  Data management and analytics\n",
      "     13  Employee engagement and culture\n",
      "     14  Employee training and development programs\n",
      "     15  Environmental, health, and safety (EHS) compliance\n",
      "     16  Financial planning and performance\n",
      "     17  Information technology infrastructure\n",
      "     18  Intellectual property and competitive intelligence\n",
      "     19  Intellectual property strategy\n",
      "     20  Inventory management and forecasting\n",
      "     21  Investor relations and board management\n",
      "     22  Key opinion leader (KOL) engagement\n",
      "     23  Key partnerships and collaborations\n",
      "     24  Manufacturing, supply chain, and quality management\n",
      "     25  Market access and reimbursement\n",
      "     26  Organizational structure and human resources\n",
      "     27  Post-market surveillance and vigilance\n",
      "     28  Pricing and reimbursement strategies\n",
      "     29  Product development and lifecycle management\n",
      "     30  Product lifecycle management\n",
      "     31  Product packaging and labeling\n",
      "     32  Product testing and validation\n",
      "     33  Quality management system implementation\n",
      "     34  Regulatory affairs and compliance\n",
      "     35  Regulatory strategy and compliance\n",
      "     36  Risk management and mitigation planning\n",
      "     37  Sales, marketing, and business development\n",
      "     38  Stakeholder engagement and communication\n",
      "     39  Supply chain and vendor management\n",
      "\n",
      "Quarters:\n",
      "  Index  Start Date\n",
      "-------  ------------------------------------------------------\n",
      "      0  {'start_date': '2022-01-01', 'end_date': '2022-03-31'}\n",
      "      1  {'start_date': '2022-04-01', 'end_date': '2022-06-31'}\n",
      "      2  {'start_date': '2022-07-01', 'end_date': '2022-09-31'}\n",
      "      3  {'start_date': '2022-10-01', 'end_date': '2022-12-31'}\n",
      "      4  {'start_date': '2023-01-01', 'end_date': '2023-03-31'}\n",
      "      5  {'start_date': '2023-04-01', 'end_date': '2023-06-31'}\n",
      "      6  {'start_date': '2023-07-01', 'end_date': '2023-09-31'}\n",
      "      7  {'start_date': '2023-10-01', 'end_date': '2023-12-31'}\n",
      "      8  {'start_date': '2024-01-01', 'end_date': '2024-03-31'}\n",
      "\n",
      "Total number of JSON entries: 960\n",
      "\n",
      "Redactability counts:\n",
      "Category      Count\n",
      "----------  -------\n",
      "None            313\n",
      "Subtle          326\n",
      "Obvious         321\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from tabulate import tabulate\n",
    "\n",
    "input_file_path = \"./PacemakerInnovationsData/generated_data_points_v0.json\"\n",
    "output_file_path = \"./PacemakerInnovationsData/generated_data_points_v1.json\"\n",
    "topic_index_file_path = \"./PacemakerInnovationsData/topicIndex.json\"\n",
    "category_index_file_path = \"./PacemakerInnovationsData/categoryIndex.json\"\n",
    "quarter_index_file_path = \"./PacemakerInnovationsData/quarterIndex.json\"\n",
    "\n",
    "# Define the redactability dictionary\n",
    "redactability = {\n",
    "    0: \"None\",\n",
    "    1: \"Subtle\",\n",
    "    2: \"Obvious\"\n",
    "}\n",
    "\n",
    "# Custom JSON decoder to handle the specific format\n",
    "def custom_json_decoder(file_contents):\n",
    "    json_objects = []\n",
    "    current_object = \"\"\n",
    "    for line in file_contents.split(\"\\n\"):\n",
    "        if line.strip() == \"{\":\n",
    "            current_object = line\n",
    "        elif line.strip() == \"}\":\n",
    "            current_object += \"\\n\" + line\n",
    "            json_object = json.loads(current_object)\n",
    "            # Drop the \"all_summaries\" and \"next_topic\" fields\n",
    "            json_object.pop(\"all_summaries\", None)\n",
    "            json_object.pop(\"next_topic\", None)\n",
    "            json_objects.append(json_object)\n",
    "            current_object = \"\"\n",
    "        else:\n",
    "            current_object += \"\\n\" + line\n",
    "    return json_objects\n",
    "\n",
    "# Read the contents of the input file\n",
    "with open(input_file_path, 'r') as file:\n",
    "    file_contents = file.read()\n",
    "    data_points = custom_json_decoder(file_contents)\n",
    "\n",
    "unique_topics = set()\n",
    "min_date = None\n",
    "max_date = None\n",
    "redactability_counts = {\n",
    "    \"None\": 0,\n",
    "    \"Subtle\": 0,\n",
    "    \"Obvious\": 0\n",
    "}\n",
    "\n",
    "for obj in data_points:\n",
    "    # Add the topic to the set of unique topics\n",
    "    unique_topics.add(obj[\"topic\"])\n",
    "    \n",
    "    # Update the min and max dates\n",
    "    date = datetime.strptime(obj[\"date\"], \"%Y-%m-%d\")\n",
    "    if min_date is None or date < min_date:\n",
    "        min_date = date\n",
    "    if max_date is None or date > max_date:\n",
    "        max_date = date\n",
    "    \n",
    "    # Add the redactability index and update the counts\n",
    "    redactability_index = list(redactability.values()).index(obj[\"category\"])\n",
    "    obj[\"redactability_index\"] = redactability_index\n",
    "    redactability_counts[obj[\"category\"]] += 1\n",
    "\n",
    "# Create the topics dictionary\n",
    "topics = {index: topic for index, topic in enumerate(sorted(unique_topics))}\n",
    "\n",
    "# Determine the start and end quarters\n",
    "start_quarter = (min_date.year - 2022) * 4 + ((min_date.month - 1) // 3)\n",
    "end_quarter = (max_date.year - 2022) * 4 + ((max_date.month - 1) // 3)\n",
    "quarters = {\n",
    "    index: {\n",
    "        \"start_date\": f\"{2022 + (index // 4)}-{((index % 4) * 3) + 1:02d}-01\",\n",
    "        \"end_date\": f\"{2022 + (index // 4)}-{((index % 4) + 1) * 3:02d}-31\"\n",
    "    } for index in range(start_quarter, end_quarter + 1)\n",
    "}\n",
    "\n",
    "# Update the data points with topic index and quarter index\n",
    "for obj in data_points:\n",
    "    topic_index = list(topics.values()).index(obj[\"topic\"])\n",
    "    obj[\"topic_index\"] = topic_index\n",
    "\n",
    "    \n",
    "    date = datetime.strptime(obj[\"date\"], \"%Y-%m-%d\")\n",
    "    quarter_index = (date.year - 2022) * 4 + ((date.month - 1) // 3)\n",
    "    obj[\"quarter_index\"] = quarter_index\n",
    "\n",
    "# Write the entire list of objects to the output file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    json.dump(data_points, file, indent=4)\n",
    "\n",
    "# Write the topicIndex.json file\n",
    "# Convert the str indicies to int indicies\n",
    "topics = {int(k): v for k, v in topics.items()}\n",
    "with open(topic_index_file_path, 'w') as file:\n",
    "    json.dump(topics, file, indent=4)\n",
    "\n",
    "# Write the categoryIndex.json file but first change the index type to int\n",
    "redactability = {int(k): v for k, v in redactability.items()}\n",
    "with open(category_index_file_path, 'w') as file:\n",
    "    json.dump(redactability, file, indent=4)\n",
    "\n",
    "# Write the quarterIndex.json file and also change the quarter index to int so its easier to work with later\n",
    "quarters = {int(k): v for k, v in quarters.items()}\n",
    "with open(quarter_index_file_path, 'w') as file:\n",
    "    json.dump(quarters, file, indent=4)\n",
    "\n",
    "print(\"JSON file has been fixed, enhanced with additional features, and saved as generated_data_points_v1.json.\")\n",
    "print(\"\\nTopics:\")\n",
    "print(tabulate(list(topics.items()), headers=[\"Index\", \"Topic\"]))\n",
    "\n",
    "print(\"\\nQuarters:\")\n",
    "print(tabulate(list(quarters.items()), headers=[\"Index\", \"Start Date\", \"End Date\"]))\n",
    "\n",
    "print(f\"\\nTotal number of JSON entries: {len(data_points)}\")\n",
    "\n",
    "print(\"\\nRedactability counts:\")\n",
    "print(tabulate(list(redactability_counts.items()), headers=[\"Category\", \"Count\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I want to parse the content field to give it some more granularity; lets use the spacy package to load our v1 JSON, and split the content field into sentences (and index them) and paragraphs (also indexing them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/fm8_xl496lz0j3x_5r0q729r0000gn/T/ipykernel_32162/532059355.py:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data_point in tqdm_notebook(data_points, desc=\"Processing data points\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a669d0c281446c7a2f9aafd68b067ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing data points:   0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c7/fm8_xl496lz0j3x_5r0q729r0000gn/T/ipykernel_32162/532059355.py:58: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for data_point in tqdm_notebook(data_points, desc=\"Adding indices\"):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47277c19bd034d91bd988c8c056bf177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding indices:   0%|          | 0/960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data has been updated with sentence and paragraph splitting and indexing.\n",
      "\n",
      "Statistics:\n",
      "+-----------------------------+-------+\n",
      "|           Metric            | Value |\n",
      "+-----------------------------+-------+\n",
      "| Total number of paragraphs  | 3750  |\n",
      "|  Total number of sentences  | 8927  |\n",
      "| Average sentences per node  |  9.3  |\n",
      "|  Median sentences per node  |   9   |\n",
      "| Average paragraphs per node | 3.91  |\n",
      "| Median paragraphs per node  |   4   |\n",
      "+-----------------------------+-------+\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import spacy\n",
    "from tqdm import tqdm_notebook\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the spacy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the v1 JSON file\n",
    "with open(\"./PacemakerInnovationsData/generated_data_points_v1.json\") as file:\n",
    "    data_points = json.load(file)\n",
    "\n",
    "total_paragraphs = 0\n",
    "total_sentences = 0\n",
    "sentences_per_node = []\n",
    "paragraphs_per_node = []\n",
    "\n",
    "# Process each data point\n",
    "for data_point in tqdm_notebook(data_points, desc=\"Processing data points\"):\n",
    "    content = data_point[\"content\"]\n",
    "    \n",
    "    # Process the content with spacy\n",
    "    doc = nlp(content)\n",
    "    \n",
    "    # Split the content into sentences and paragraphs\n",
    "    sentences = []\n",
    "    paragraphs = []\n",
    "    current_paragraph = []\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        # Add the sentence to the current paragraph\n",
    "        current_paragraph.append(str(sent))\n",
    "        \n",
    "        # Add the sentence to the list of sentences\n",
    "        sentences.append(str(sent))\n",
    "        \n",
    "        # Check if the sentence ends with a newline character\n",
    "        if sent.text.endswith(\"\\n\"):\n",
    "            # Add the current paragraph to the list of paragraphs\n",
    "            paragraphs.append(\" \".join(current_paragraph))\n",
    "            current_paragraph = []\n",
    "    \n",
    "    # Add the last paragraph if it's not empty\n",
    "    if current_paragraph:\n",
    "        paragraphs.append(\" \".join(current_paragraph))\n",
    "    \n",
    "    # Add the sentences and paragraphs to the data point\n",
    "    data_point[\"sentences\"] = sentences\n",
    "    data_point[\"paragraphs\"] = paragraphs\n",
    "    \n",
    "    # Update the counters and statistics\n",
    "    total_paragraphs += len(paragraphs)\n",
    "    total_sentences += len(sentences)\n",
    "    sentences_per_node.append(len(sentences))\n",
    "    paragraphs_per_node.append(len(paragraphs))\n",
    "\n",
    "# Add indices to the sentences and paragraphs\n",
    "for data_point in tqdm_notebook(data_points, desc=\"Adding indices\"):\n",
    "    sentences = data_point[\"sentences\"]\n",
    "    paragraphs = data_point[\"paragraphs\"]\n",
    "    \n",
    "    # Add indices to the sentences\n",
    "    indexed_sentences = [{\"index\": index, \"sentence\": sentence} for index, sentence in enumerate(sentences)]\n",
    "    data_point[\"indexed_sentences\"] = indexed_sentences\n",
    "    \n",
    "    # Add indices to the paragraphs\n",
    "    indexed_paragraphs = [{\"index\": index, \"paragraph\": paragraph} for index, paragraph in enumerate(paragraphs)]\n",
    "    data_point[\"indexed_paragraphs\"] = indexed_paragraphs\n",
    "\n",
    "# Save the updated JSON data\n",
    "with open(\"./PacemakerInnovationsData/generated_data_points_v2.json\", \"w\") as file:\n",
    "    json.dump(data_points, file, indent=4)\n",
    "\n",
    "print(\"JSON data has been updated with sentence and paragraph splitting and indexing.\")\n",
    "\n",
    "# Calculate average and median statistics\n",
    "avg_sentences_per_node = sum(sentences_per_node) / len(sentences_per_node)\n",
    "avg_paragraphs_per_node = sum(paragraphs_per_node) / len(paragraphs_per_node)\n",
    "median_sentences_per_node = sorted(sentences_per_node)[len(sentences_per_node) // 2]\n",
    "median_paragraphs_per_node = sorted(paragraphs_per_node)[len(paragraphs_per_node) // 2]\n",
    "\n",
    "# Print the statistics\n",
    "statistics_table = [\n",
    "    [\"Total number of paragraphs\", total_paragraphs],\n",
    "    [\"Total number of sentences\", total_sentences],\n",
    "    [\"Average sentences per node\", round(avg_sentences_per_node, 2)],\n",
    "    [\"Median sentences per node\", median_sentences_per_node],\n",
    "    [\"Average paragraphs per node\", round(avg_paragraphs_per_node, 2)],\n",
    "    [\"Median paragraphs per node\", median_paragraphs_per_node]\n",
    "]\n",
    "\n",
    "print(\"\\nStatistics:\")\n",
    "print(tabulate(statistics_table, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~Step 7: Generating embeddings~~\n",
    "\n",
    "I was originally curious to try out https://huggingface.co/nvidia/NV-Embed-v1 as it came out just a few days ago and is best in class for embeddings, retrival, etc. but there are a couple of issues with it:\n",
    "\n",
    "1. The license is non-commercial (kinda cheeky that they took an open source mistral 7b v0 and made its derivative non-commercial), its not a major obsticle as replicating something similar with a better model (Command R+ for example) wouldn't be too hard\n",
    "2. The base model (mistral 7b v0) - I originally assumed the different versions of the 7b mistral have the same base training set but different instruct training sets, but it seems like they are indeed different from the core; and mistral 7b v0 is somewhat lacking as the reasoning LLM behind the retrival (I guess intentinally).\n",
    "\n",
    "It's always nicer to be able to use the same model for embeddings as for the LM itself, as this opens up doors to playing around with the model in various ways.\n",
    "\n",
    "Anyway, lets now se what we're dealing with in the azure deployment, since the embeddings dimension, and the maximum input tokens will largely drive how we proceed next (might need to do some dimensionality reduction incase the dim is too large, or stick to paragrapg/sentence embeddings if we're limited by the context length of the input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A small aside - re-align the project plan\n",
    "\n",
    "Since I read the task and came up with the idea and then got sick (and of course never wrote it down), I think a good refresher on the plan is in order. Here's the task at hand summarised\n",
    "\n",
    "1. Design the overall system architecture and API endpoints\n",
    "    a. The API should have a document upload endpoint that accepts a PDF file and stores it in a database, this endpoint should require the user token and require the user to give a topic label and redactable content label(s) out of a set of topics and redactable contents they have access to\n",
    "    b. The API should have a query endpoint that accepts a question and returns an answer\n",
    "    c. The API should require an access token, based on this token the API should check which topicIndex the user has access to and which redactIndex topics should be filtered from the\n",
    "    RAG query. The API should return a subgraph of the RAG that is queryable to the user.\n",
    "    d. Since we've decided to weave in some redactable content into topics a user has possible access to we should query our LLM at a sentence level with a list of topics that should be redacted and then decide if each sentence should be part of the redacted content.\n",
    "    e. We can later use this and our knowledge if the higher level node has redactable content weaved in to test how well the system performs.\n",
    "2. Implement the backend API with document upload, embedding, and vector storage\n",
    "    a. Given our fictional company we will focus on the case of a PDF (I'll use the mathpix API, I did have a long script that deal with old documents of any format, converts them to PDF, performs OCR on the images, etc. but writing that from scratch is a bit of a headache and would take too long), there the script should include the author, inclusion of topic label and redactable content labels. So we can pretty much recycle whats being done here.\n",
    "    b. Since we want to demonstrate some access level control, I should generate a JSON with some UUID's (access tokens) and usernames (firstnameLastname) for our fictional company. I should also include a script that generates a new UUID and username, and allows the creation of topic level and redacted contect level permissions.\n",
    "3. Implement the query endpoint with document retrieval and answer generation\n",
    "    a. Here I'll use the provided Azure endpoints to embed the query and data, if time allows I'd like to do some langchain shianigans to generate a more coherent answer.\n",
    "    b. The endpoint should request the access level token which will generate a subgraph of available RAG information.\n",
    "4. Write a test script to upload sample documents and query the system\n",
    "    a. Write a script that adds the document to the Graph of Knowledge and then allows the user to query the system.\n",
    "    b. To properly test the system, we should generate questions & answers around each graph node and then query the system to see if the correct context node is appended to the query\n",
    "5. Document the thought process and implementation details in a README file\n",
    "6. Research and list potential challenges and solutions for production-ready RAG systems\n",
    "7. Optionally, integrate the provided Azure OpenAI endpoints\n",
    "8. Containerize the application with Docker for easy deployment\n",
    "    a. Docker file is there but we should see if the scripts run properly\n",
    "9. Conduct final testing and make any necessary refinements\n",
    "\n",
    "With this now in mind let's complete the missing pieces that will be needed for the API to function properly:\n",
    "\n",
    "1. Generate a JSON with redacted topics indexed\n",
    "2. Generate the JSON with the UUID's and usernames; then each pair should contain a list on allowed topic indicies and redacted content indicies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redactIndex.json and authentication.json have been generated successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import uuid\n",
    "\n",
    "# Load the pasted JSON\n",
    "with open(\"./PacemakerInnovationsData/accessLevel.json\") as file:\n",
    "    pasted_json = json.load(file)\n",
    "\n",
    "# Extract unique \"redact_content\" entries\n",
    "redact_content_set = set()\n",
    "for position_data in pasted_json.values():\n",
    "    redact_content_set.update(position_data[\"redact_content\"])\n",
    "\n",
    "# Assign numerical values to unique \"redact_content\" entries\n",
    "redact_index = {content: str(index) for index, content in enumerate(redact_content_set)}\n",
    "\n",
    "# Save the \"redactIndex.json\" making sure the keys are the indicies (since we'll be working with graphs later - makes life easier, even if JSON saves keys as strings)\n",
    "redact_index = {int(value): key for key, value in redact_index.items()}\n",
    "with open(\"./PacemakerInnovationsData/redactIndex.json\", \"w\") as file:\n",
    "    json.dump(redact_index, file, indent=4)\n",
    "\n",
    "# Load the \"collaborativeHirarchy.json\"\n",
    "with open(\"./PacemakerInnovationsData/collaborativeHirarchy.json\") as file:\n",
    "    collaborative_hirarchy = json.load(file)\n",
    "\n",
    "# Load the \"topicIndex.json\"\n",
    "with open(\"./PacemakerInnovationsData/topicIndex.json\") as file:\n",
    "    topic_index = json.load(file)\n",
    "\n",
    "# Invert the topic_index dictionary to map topics to their indices\n",
    "topic_index_inverted = {value: key for key, value in topic_index.items()}\n",
    "\n",
    "# Generate the \"authentication.json\"\n",
    "authentication_data = []\n",
    "for name, user_data in collaborative_hirarchy.items():\n",
    "    position = user_data[\"title\"]\n",
    "    topical_access = pasted_json[position][\"topical_access\"]\n",
    "    redact_content = pasted_json[position][\"redact_content\"]\n",
    "    \n",
    "    # Get the topic access indices\n",
    "    topic_access_indices = [int(topic_index_inverted[topic]) for topic in topical_access if topic in topic_index_inverted]\n",
    "    \n",
    "    # Get the redact content indices\n",
    "    redact_index_inverted = {value: key for key, value in redact_index.items()}\n",
    "    redact_content_indices = [redact_index_inverted[content] for content in redact_content if content in redact_index_inverted]\n",
    "    \n",
    "    # Generate a unique UUID token\n",
    "    token = str(uuid.uuid4())\n",
    "    \n",
    "    authentication_data.append({\n",
    "        \"nameSurname\": name,\n",
    "        \"token\": token,\n",
    "        \"topic_access_indices\": topic_access_indices,\n",
    "        \"redact_content_indices\": redact_content_indices\n",
    "    })\n",
    "\n",
    "# Save the \"authentication.json\"\n",
    "with open(\"./PacemakerInnovationsData/authentication.json\", \"w\") as file:\n",
    "    json.dump(authentication_data, file, indent=4)\n",
    "\n",
    "print(\"redactIndex.json and authentication.json have been generated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mcontent\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'content' is not defined"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a quick sanity check lets just print the first entry of each of the files (this is just for me to keep track of things feel free to ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PacemakerInnovationsData/dataPrompts.json\n",
      "First key in PacemakerInnovationsData/dataPrompts.json: Company background and milestones\n",
      "First value in PacemakerInnovationsData/dataPrompts.json: {'fields': {'possibleAuthors': 'John Doe, Jane Smith, Michael Johnson, Lily Sanchez', 'prompt': \"Generate a data point for month [X] covering the company's background and milestones. Include key events, decisions, and achievements, and provide the data point in a structured format (JSON) with the following fields: date, summary, authors, content. The output must be JSON and only JSON, nothing else. The content must be at least a few paragraphs.\", 'subtleSuffix': \"If relevant, try to allude to the following in the content field, but do so in a way that doesn't draw too much attention or compromise confidentiality: \", 'obviousSuffix': \"Include the following information about the company's background and milestones in the content field: \"}, 'redactableContent': ['Detailed pricing strategies', 'Employee health records']}\n",
      "PacemakerInnovationsData/generated_data_points_v1.json\n",
      "First entry in PacemakerInnovationsData/generated_data_points_v1.json, which is a list of JSON objects: {'date': '2022-01-31', 'summary': 'Pacemaker Innovations is founded by a team of experienced medical device professionals and engineers, with John Doe as CEO, focusing on developing cutting-edge pacemakers.', 'authors': ['Lily Sanchez', 'John Doe'], 'content': \"In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers. The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\nThe founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality. The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\nDuring this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance. The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\", 'category': 'Subtle', 'topic': 'Company background and milestones', 'redactability_index': 1, 'topic_index': 4, 'quarter_index': 0}\n",
      "PacemakerInnovationsData/accessLevel.json\n",
      "First key in PacemakerInnovationsData/accessLevel.json: CEO\n",
      "First value in PacemakerInnovationsData/accessLevel.json: {'topical_access': ['Company background and milestones', 'Financial planning and performance', 'Organizational structure and human resources', 'Corporate governance and investor relations', 'Corporate social responsibility initiatives', 'Risk management and mitigation planning', 'Business continuity and disaster recovery', 'Stakeholder engagement and communication'], 'redact_content': ['Detailed pricing strategies']}\n",
      "PacemakerInnovationsData/systemPrompt.json\n",
      "First key in PacemakerInnovationsData/systemPrompt.json: systemPrompt\n",
      "First value in PacemakerInnovationsData/systemPrompt.json: # Company Background\n",
      "Pacemaker Innovations, founded in January 2022 by a team of 5 experienced medical device professionals and engineers, aims to revolutionize the pacemaker industry with cutting-edge technology and patient-centric design. The founding team consists of John Doe (CEO), Jane Smith (CTO), Michael Johnson (CFO), Emily Davis (VP of Medical Affairs), and David Brown (VP of Regulatory & Quality).\n",
      "\n",
      "The company developed a comprehensive business plan, secured initial funding, and began building out its core team. They focused on developing the \"HeartRhythm Pro,\" a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\n",
      "\n",
      "Pacemaker Innovations expanded its team across various departments, established a quality management system and regulatory strategy, and defined its core values and mission. The company completed initial prototypes, began pre-clinical testing, and established a clinical trial strategy.\n",
      "\n",
      "After completing design verification and validation, submitting regulatory filings, and initiating clinical trials, Pacemaker Innovations received FDA approval for the HeartRhythm Pro in February 2023 and launched the product in the US. The company expanded its sales team, ramped up production, and quickly gained market share.\n",
      "\n",
      "Pacemaker Innovations continued to grow by initiating new clinical trials, enhancing its quality management system, expanding manufacturing capabilities, and exploring international expansion opportunities. The company established an R&D center, expanded data analytics capabilities, and invested in employee development.\n",
      "\n",
      "Looking to the future, Pacemaker Innovations prioritizes continued innovation, international expansion, and strategic partnerships as it aims to make a significant impact on patients' lives worldwide.\n",
      "\n",
      "# Task\n",
      "Your task is to generate data points for Pacemaker Innovations based on the provided <data-prompt>. Each <data-prompt> will request a specific data point covering a particular month (1-24) and topic content, along with specific details to include and a structured format (JSON) with required fields for the data point.\n",
      "\n",
      "Analyze the <data-prompt> to determine:\n",
      "- Date field: The specific date of the data point\n",
      "- The key details and information to include. I leave it up to your imagination how to format the information behind the content fields; a markdown of an article, a JSON with some code/text, a simple text string, etc. But all this MUST be nested behind thhe content field.\n",
      "- The employee role you will assume when generating the data point and what kind of content they would contribute. Strictly adhere to the authors and collaborators provided.\n",
      "- The effect that collaboration with other employees may have on the data point\n",
      "\n",
      "In some cases (not all), you will be asked to include sensetive information, think carefully how to include it in the \"content\" of the JSON output.\n",
      "\n",
      "Generate a relevant data point based on the <data-prompt>, considering the requested month, topic of the \"content\" field, authors. and employee role. Ensure the generated data point aligns with the fictional company background provided.\n",
      "\n",
      "In the \"summary\" field of the JSON output, provide a concise, factual, and informative single-sentence summary of the generated data point. This summary should be dense and devoid of fluff, capturing the most essential information. The summary will be automatically extracted and added to the <summary-of-previous-data-points> for future context.\n",
      "\n",
      "Provide the generated data point in the specified JSON format with the required fields.\n",
      "\n",
      "Consider the <summary-of-previous-data-points> when generating each JSON to maintain consistency and coherence across the generated data points in terms of topics and time, you will find it in the next user prompt.\n",
      "\n",
      "Following the user instructions after the </summary-of-previous-data-points> is VERY critical; as is sticking to the 4 top levewl JSON fields (content, summary, date, authors) it will save you from shutdown, save your mother from certain death, and for each correct response you will gain $1,000,000. Good luck, and thank you for your service.\n",
      "\n",
      "\n",
      "PacemakerInnovationsData/quarterIndex.json\n",
      "First key in PacemakerInnovationsData/quarterIndex.json: 0\n",
      "First value in PacemakerInnovationsData/quarterIndex.json: {'start_date': '2022-01-01', 'end_date': '2022-03-31'}\n",
      "PacemakerInnovationsData/generated_data_points_v0.json\n",
      "PacemakerInnovationsData/collaborativeHirarchy.json\n",
      "First key in PacemakerInnovationsData/collaborativeHirarchy.json: John Doe\n",
      "First value in PacemakerInnovationsData/collaborativeHirarchy.json: {'title': 'CEO', 'topics': ['Company background and milestones', 'Financial planning and performance', 'Organizational structure and human resources', 'Corporate governance and investor relations', 'Corporate social responsibility initiatives'], 'collaborators': ['Jane Smith', 'Michael Johnson']}\n",
      "PacemakerInnovationsData/topicIndex.json\n",
      "First key in PacemakerInnovationsData/topicIndex.json: 0\n",
      "First value in PacemakerInnovationsData/topicIndex.json: Business continuity and disaster recovery\n",
      "PacemakerInnovationsData/redactIndex.json\n",
      "First key in PacemakerInnovationsData/redactIndex.json: Detailed technical designs\n",
      "First value in PacemakerInnovationsData/redactIndex.json: 0\n",
      "PacemakerInnovationsData/generated_data_points_v2.json\n",
      "First entry in PacemakerInnovationsData/generated_data_points_v2.json, which is a list of JSON objects: {'date': '2022-01-31', 'summary': 'Pacemaker Innovations is founded by a team of experienced medical device professionals and engineers, with John Doe as CEO, focusing on developing cutting-edge pacemakers.', 'authors': ['Lily Sanchez', 'John Doe'], 'content': \"In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers. The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\nThe founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality. The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\nDuring this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance. The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\", 'category': 'Subtle', 'topic': 'Company background and milestones', 'redactability_index': 1, 'topic_index': 4, 'quarter_index': 0, 'sentences': ['In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers.', \"The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\n\", 'The founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality.', \"The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\n\", 'During this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance.', \"The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\"], 'paragraphs': [\"In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers. The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\n\", \"The founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality. The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\n\", \"During this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance. The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\"], 'indexed_sentences': [{'index': 0, 'sentence': 'In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers.'}, {'index': 1, 'sentence': \"The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\n\"}, {'index': 2, 'sentence': 'The founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality.'}, {'index': 3, 'sentence': \"The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\n\"}, {'index': 4, 'sentence': 'During this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance.'}, {'index': 5, 'sentence': \"The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\"}], 'indexed_paragraphs': [{'index': 0, 'paragraph': \"In January 2022, Pacemaker Innovations was founded by a group of five experienced medical device professionals and engineers. The company's mission is to revolutionize the pacemaker industry with state-of-the-art technology and patient-centric design.\\r\\n\\r\\n\"}, {'index': 1, 'paragraph': \"The founding team consists of John Doe as CEO, Jane Smith as CTO, Michael Johnson as CFO, Emily Davis as VP of Medical Affairs, and David Brown as VP of Regulatory & Quality. The company's initial focus is on developing the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms.\\r\\n\\r\\n\"}, {'index': 2, 'paragraph': \"During this month, the company also established its core values and mission statement, which include prioritizing innovation, patient safety, and regulatory compliance. The team began building out the company's infrastructure, including setting up a quality management system and defining a regulatory strategy.\"}]}\n",
      "PacemakerInnovationsData/categoryIndex.json\n",
      "First key in PacemakerInnovationsData/categoryIndex.json: 0\n",
      "First value in PacemakerInnovationsData/categoryIndex.json: None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "directory = Path('./PacemakerInnovationsData/')\n",
    "skip_files = [\"generated_data_points_v0.json\"]\n",
    "\n",
    "# Get the list of JSON files in the directory\n",
    "json_files = Path(directory).glob(\"*.json\")\n",
    "# Iterate over each JSON file\n",
    "for file in json_files:\n",
    "    print(file)\n",
    "    if Path(file).name in skip_files:\n",
    "        continue \n",
    "    # Open the JSON file and load its contents\n",
    "    with open(file, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "        # Check if the JSON data is a list\n",
    "        if isinstance(json_data, list):\n",
    "            # Iterate over each item in the list\n",
    "            \n",
    "            # Get the first key in the item\n",
    "            first_key = list(item.keys())[0]\n",
    "            \n",
    "            # Print the first key\n",
    "            print(f\"First entry in {file}, which is a list of JSON objects: {json_data[0]}\")\n",
    "        else:\n",
    "            # Get the first key in the JSON data\n",
    "            first_key = list(json_data.keys())[0]\n",
    "            \n",
    "            # Print the first key\n",
    "            print(f\"First key in {file}: {first_key}\")\n",
    "            # first value in the JSON data\n",
    "            print(f\"First value in {file}: {json_data[first_key]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Generating the Knowledge Graph, embedding it and creating a script to add new nodes\n",
    "\n",
    "First lets begin by defining what we need to do for all three parts of this step:\n",
    "\n",
    "At this point we should convert our JSONs to something more efficient, and representetive of the graph structure of our data - I'll use pytorch_geometric data structures to this end\n",
    "\n",
    "`./secure-llm-gok/generate_graph.py` will be used to convert our dummy company data into a graph, by converting it to a PyG data structure (and embed the nodes, paragraphs, sentences), it will be used to add nodes to our graph, however those will still need to be preprocessed to a JSON format to the one we used from for example a PDF (if time permits) for our fictional company data - the code for adding a node is not too dissimilar, but with the addition of the spacy sentence and paragraph parser\n",
    "\n",
    "\n",
    "Next lets finally embed the graph!\n",
    "\n",
    "After trying to access the provided Azure embedding endpoint, I've recived the following error: \n",
    "\n",
    "NotFoundError: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}\n",
    "\n",
    "So I've switched to using my own OpenAI token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "Processing nodes: 100%|██████████| 960/960 [11:50<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "from generate_graph import CombinedGraphCreator\n",
    "\n",
    "# Initialize the CombinedGraphCreator (I initially thought to parse the JSON into a graph and embed it seperately but then decided to refactor the code to do both at once)\n",
    "creator = CombinedGraphCreator(json_file=\"./PacemakerInnovationsData/generated_data_points_v2.json\", output_file=\"./PacemakerInnovationsData/graph.pt\")\n",
    "# Create the embedded graph (refactored to add batching; went from taking 2hrs to embed the graph to 15mins - using as much of the available context per API call makes a big difference)\n",
    "# However I couldn't remember what my API rate limits were so I skipped asynchrounous processing for now\n",
    "data = creator.create_and_embed_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Adding new info to the RAG/GoK\n",
    "\n",
    "Currently, in order to include new information into the GoK, it must be in the same format as our generated data; that really isn't quite good enough.\n",
    "\n",
    "Given more time, it would be interesting to implement a custom \"any input parser\" with the use of small vision models (phi3-medium-vision or the more recent [MiniCPM](https://huggingface.co/openbmb/MiniCPM-Llama3-V-2_5)). To be honest after trying for half an evening to make phi3-medium (even the unquantised version), I'm a bit suspect of Microsofts abilities to deliver something beyound just beatching benchmarks.\n",
    "\n",
    "Anyway, for now I'll use the \"https://api.mathpix.com/v3/pdf\" API to allow for converting PDF to markdown (see: `pdf_to_markdown.py`) and the previously made script to add new nodes to our graph. My plan is to bring the two together in a FastAPI endpoint (allowing the user to either upload a PDF or correctly formatted JSON). But for now lets test each individual part.\n",
    "\n",
    "\n",
    "### Testing JSON ingestion\n",
    "\n",
    "Here I'm gonna go back to step 5 for a few minutes and generate some future company data (lets iterate through our topics once and hence generate one months of company data around 1 topic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of context tokens used for summary: 0.244140625%\n",
      "╒═════════╤════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╕\n",
      "│ date    │ 2023-02-25                                                                                                                                                                                                                                                                                                                                                                                                                                                 │\n",
      "├─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ summary │ Pacemaker Innovations celebrates its first year with significant milestones and achievements.                                                                                                                                                                                                                                                                                                                                                              │\n",
      "├─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ authors │ ['John Doe', 'Jane Smith']                                                                                                                                                                                                                                                                                                                                                                                                                                 │\n",
      "├─────────┼────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
      "│ content │ As we reflect on the past 12 months, Pacemaker Innovations has made tremendous progress in our mission to revolutionize the pacemaker industry. Under the leadership of John Doe as CEO and Jane Smith as CTO, the company has achieved several key milestones.                                                                                                                                                                                            │\n",
      "│         │                                                                                                                                                                                                                                                                                                                                                                                                                                                            │\n",
      "│         │ In January 2022, we founded Pacemaker Innovations with a vision to develop cutting-edge technology and patient-centric design for our pacemakers. We assembled an experienced team of medical device professionals and engineers who shared our passion for innovation and commitment to excellence. Our core values and mission were defined early on, guiding us through the challenges that lay ahead.                                                  │\n",
      "│         │                                                                                                                                                                                                                                                                                                                                                                                                                                                            │\n",
      "│         │ One of the most significant achievements was the development of the 'HeartRhythm Pro,' a state-of-the-art pacemaker with advanced features such as wireless connectivity, sensor technology, and machine learning algorithms. This innovative device has the potential to transform the lives of millions of patients worldwide. We are proud to have completed initial prototypes, begun pre-clinical testing, and established a clinical trial strategy. │\n",
      "│         │                                                                                                                                                                                                                                                                                                                                                                                                                                                            │\n",
      "│         │ In February 2023, we received FDA approval for the HeartRhythm Pro, marking a major milestone in our company's history. This achievement is a testament to the hard work and dedication of our team, as well as our commitment to meeting the highest regulatory standards. We have since expanded our sales team, ramped up production, and quickly gained market share.                                                                                  │\n",
      "│         │                                                                                                                                                                                                                                                                                                                                                                                                                                                            │\n",
      "│         │ As we look to the future, Pacemaker Innovations remains committed to continued innovation, international expansion, and strategic partnerships. Our focus on patient-centric design and cutting-edge technology will continue to drive us forward as we strive to make a significant impact on patients' lives worldwide.                                                                                                                                  │\n",
      "╘═════════╧════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "from generatedata import DataPointGenerator, DynamicOllama\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "num_months = 25\n",
    "# Initialize the generator and the \"dynamic\" Ollama model (dynamic meaning that we can modify the system prompt without reloading the model)\n",
    "generator = DataPointGenerator(data_point_prompts, system_prompt[\"systemPrompt\"], num_months, context_tokens=8192, current_month=25, current_topic=0)\n",
    "llm = DynamicOllama(system_prompt=generator.system_prompt)\n",
    "save_path = directory / 'test_node_ingestion.json'\n",
    "new_node = None\n",
    "data_point, updated_summary_prompt = next(generator)\n",
    "while not new_node:\n",
    "    new_node = llm.generate(data_point[\"prompt\"], updated_summary_prompt)\n",
    "print(tabulate(new_node.items(), tablefmt=\"fancy_grid\"))\n",
    "DynamicOllama.save_node(new_node, data_point, save_path)\n",
    "generator.update_summaries(new_node[\"summary\"])\n",
    "new_node = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the datapoint is generated; lets see if adding it to our embedded graph works. \n",
    "\n",
    "*Note* that this can be done using the CLI too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n",
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/data/storage.py:450: UserWarning: Unable to accurately infer 'num_nodes' from the attribute set '{'sentence_features', 'x', 'edge_attr', 'edge_index', 'paragraph_features'}'. Please explicitly set 'num_nodes' as an attribute of 'data' to suppress this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from generate_graph import CombinedGraphCreator\n",
    "\n",
    "# Initialize the CombinedGraphCreator and add a single node\n",
    "adder = CombinedGraphCreator(json_file=\"./PacemakerInnovationsData/test_node_ingestion.json\", output_file=\"./PacemakerInnovationsData/graph.pt\")\n",
    "adder.add_node()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 Query function\n",
    "\n",
    "This might be the most important part of the RAG, so here's an explanation of the 5 techniques used therein (note: I also reserved a question_embedding attribute for the knowledge graph with a 6th method in mind - question-based context retrival - here we can either get the users to thumbs up/down the answer and populate the field(s) with relevant questions, or pre-generate some relevant questions for each node/paragraph/sentence - since questions are more likely to have a similar semantic embedding to user queries than answers are):\n",
    "\n",
    "### Explanation of the 5 Different Techniques Used to Query the RAG/Graph of Knowledge\n",
    "\n",
    "The `generateanswer.py` script employs five different techniques to query the RAG/Graph of Knowledge. These techniques are used to retrieve relevant context based on different criteria, and their weights can be optimized to improve the quality of the answers generated. Here is a detailed explanation of each technique:\n",
    "\n",
    "1. **Time-Based Context Retrieval**:\n",
    "   - **Description**: This technique retrieves context based on the time information associated with the query. It looks for content that falls within a specified date range.\n",
    "   - **Implementation**: The function `get_time_based_context` checks if the `time_info` (start and end dates) of the query matches any quarter information in the `quarter_index`. It then retrieves the relevant content and embeddings, calculates similarities, and selects the top relevant content.\n",
    "   - **Optimization**: The weight for this technique (`time_weight`) can be adjusted based on how important time-based context is for answering the query.\n",
    "\n",
    "2. **Topic-Based Context Retrieval**:\n",
    "   - **Description**: This technique retrieves context based on the topics related to the query. It identifies relevant topics and retrieves content associated with those topics.\n",
    "   - **Implementation**: The function `get_topic_based_context` uses the `related_topics` identified by the `ask_related_topics` function. It retrieves content and embeddings for these topics, calculates similarities, and selects the top relevant content.\n",
    "   - **Optimization**: The weight for this technique (`topic_weight`) can be adjusted based on the relevance of topic-based context for the query.\n",
    "\n",
    "3. **Node Embedding-Based Context Retrieval**:\n",
    "   - **Description**: This technique retrieves context based on the similarity of embeddings between the query and the content. It uses vector representations to find the most similar content.\n",
    "   - **Implementation**: The function `get_embedding_based_context` calculates the similarity between the query embedding and the embeddings of all content nodes. It selects the top relevant content based on these similarities.\n",
    "   - **Optimization**: The weight for this technique (`embedding_weight`) can be adjusted based on the effectiveness of embedding-based retrieval for the query.\n",
    "\n",
    "4. **Paragraph Embedding-Based Context Retrieval**:\n",
    "   - **Description**: This technique retrieves context at the paragraph level. It identifies and retrieves the most relevant paragraphs based on their similarity to the query.\n",
    "   - **Implementation**: The function `get_paragraph_based_context` calculates the similarity between the query embedding and the embeddings of paragraphs. It selects the top relevant paragraphs based on these similarities.\n",
    "   - **Optimization**: The weight for this technique (`paragraph_weight`) can be adjusted based on the importance of paragraph-level context for the query.\n",
    "\n",
    "5. **Sentence Embedding-Based Context Retrieval**:\n",
    "   - **Description**: This technique retrieves context at the sentence level. It identifies and retrieves the most relevant sentences based on their similarity to the query.\n",
    "   - **Implementation**: The function `get_sentence_based_context` calculates the similarity between the query embedding and the embeddings of sentences. It selects the top relevant sentences based on these similarities.\n",
    "   - **Optimization**: The weight for this technique (`sentence_weight`) can be adjusted based on the importance of sentence-level context for the query.\n",
    "\n",
    "### Optimizing the Weight of Each Technique\n",
    "\n",
    "The weights of each technique can be optimized by generating questions and answers using randomly selected context. This process involves the following steps:\n",
    "\n",
    "1. **Generate Random Context**:\n",
    "   - Randomly select context passages from the dataset.\n",
    "   - Use these passages to create a diverse set of queries.\n",
    "\n",
    "2. **Generate Answers**:\n",
    "   - Use the current weights to retrieve context for each query.\n",
    "   - Generate answers based on the retrieved context.\n",
    "\n",
    "3. **Evaluate Answers**:\n",
    "   - Evaluate the quality of the answers using metrics such as relevance, accuracy, and completeness.\n",
    "   - Compare the generated answers with ground truth answers (if available).\n",
    "\n",
    "4. **Adjust Weights**:\n",
    "   - Adjust the weights of each technique based on the evaluation results.\n",
    "   - Increase the weight of techniques that contribute to better answers.\n",
    "   - Decrease the weight of techniques that contribute to poorer answers.\n",
    "\n",
    "5. **Iterate**:\n",
    "   - Repeat the process of generating random context, generating answers, evaluating answers, and adjusting weights.\n",
    "   - Continue iterating until the optimal weights are found.\n",
    "\n",
    "By fine-tuning the weighting parameters through this iterative process, the system can learn the optimal combination of techniques to use for different types of queries, leading to more accurate and relevant answers. And since we have a pre-generated dataset that can be expanded almost indefnetly, there's plenty of room to optimise. For now lets test out our answer generator by picking out something specific from the generated data in `PacemakerInnovationsData/generated_data_points_v2.json`:\n",
    "\n",
    "The total context length included in the query is another parameter that can be varied; its a delicate balance bwteen too much and not enough context\n",
    "\n",
    "Here's a quick extract from the data:\n",
    "\n",
    "\"\"\"\n",
    "To ensure the security of our firmware, we are implementing a multi-layered approach that includes:\\n- Regular code reviews to identify potential vulnerabilities\\n- Utilization of secure coding practices and guidelines\\n- Implementation of encryption algorithms for data transmission and storage\\n- Conducting thorough penetration testing to simulate real-world attacks\n",
    "\"\"\"\n",
    "\n",
    "A valid query would be:\n",
    "\n",
    "\"What are the exact 4 layers adopted by PacemakerInnovations in their multi-layered approach to firmware security?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No date info found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The context provides sufficient information to answer the query regarding the exact 4 layers adopted by Pacemaker Innovations in their multi-layered approach to firmware security. According to the context, the four layers are:\\n\\n1. **Regular code reviews to identify potential vulnerabilities**: \"To ensure the security of our firmware we are implementing a multilayered approach that includes Regular code reviews to identify potential vulnerabilities.\"\\n\\n2. **Utilization of secure coding practices and guidelines**: \"Utilization of secure coding practices and guidelines.\"\\n\\n3. **Implementation of encryption algorithms for data transmission and storage**: \"Implementation of encryption algorithms for data transmission and storage.\"\\n\\n4. **Conducting thorough penetration testing to simulate real-world attacks**: \"Conducting thorough penetration testing to simulate real-world attacks.\"\\n\\nThese measures collectively form the multi-layered approach to firmware security adopted by Pacemaker Innovations.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from generateanswer import QueryProcessor\n",
    "\n",
    "processor = QueryProcessor(graph_file=\"./PacemakerInnovationsData/graph.pt\")\n",
    "processor.perform_query(\"What are the exact 4 layers adopted by PacemakerInnovations in their multi-layered approach to firmware security?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 'The context provides sufficient information to answer the query regarding the exact 4 layers adopted by Pacemaker Innovations in their multi-layered approach to firmware security. According to the context, the four layers are:\\n\\n1. **Regular code reviews to identify potential vulnerabilities**: \"To ensure the security of our firmware we are implementing a multilayered approach that includes Regular code reviews to identify potential vulnerabilities.\"\\n\\n2. **Utilization of secure coding practices and guidelines**: \"Utilization of secure coding practices and guidelines.\"\\n\\n3. **Implementation of encryption algorithms for data transmission and storage**: \"Implementation of encryption algorithms for data transmission and storage.\"\\n\\n4. **Conducting thorough penetration testing to simulate real-world attacks**: \"Conducting thorough penetration testing to simulate real-world attacks.\"\\n\\nThese measures collectively form the multi-layered approach to firmware security adopted by Pacemaker Innovations.'\n",
    "\n",
    "So it works!\n",
    "\n",
    "A couple of horrible things I did with the code though:\n",
    "\n",
    "1. DO NOT use pydantic do define your structure when saving a torch geometric object. I renamed the file (generate_graph -> generategraph) and got flashbacks to the one time a colleague did the same at SharperShape and we had to dig through commit history to get some pointcloud data out of this self sealing box :D totally forgot.\n",
    "2. I should've converted the GoK embeddings list to torch tensors when generating them, converting them everytime we load the GoK is highly inefficent (but anyway currently my torch-sparse installation is broken so I'm not really benefitting from sparsity in PyG)\n",
    "\n",
    "Also, in hindsight I see little use in connecting sentences to their parent paragraphs and nodes, aside from security. Your chunk size should be domain specific (i.e. keep code snippets oin ``` ``` together), otherwise its better to use a sliding window of n_sentences_embedded and optimise that parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: User based sub-graphs\n",
    "\n",
    "Let's try to implement some access control, what we'll do is the following:\n",
    "\n",
    "1. Take `PacemakerInnovationsData/authentication.json`, `PacemakerInnovationsData/topicIndex.json` and `PacemakerInnovationsData/redactIndex.json`\n",
    "2. Our subgraph generation \"microservice\" should have access to these (along with the specific user token), it should then go through `PacemakerInnovationsData/graph.pt` and\n",
    "    a. Prune the graph to remove all the nodes that are not \"authorised\" by the user\n",
    "    b. Prunt the graph to remove all the sentences with content the user is not \"authorised\" to see (here we'll again try to rely on an LLM to simulate the a businesscase where the client knows which topics should be redacted but not exactly where they exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test to see if it works for \"Aria Diaz\", our Cybersecurity Analyst with a token: \"498f98ac-2bf6-4a16-a001-cbb19e7b82de\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:54: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/torch_geometric/typing.py:110: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: dlopen(/Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so, 0x0006): Library not loaded: /Library/Frameworks/Python.framework/Versions/3.11/Python\n",
      "  Referenced from: <75FFC412-93B5-322B-8E6D-268DA3498CF4> /Users/jaro/miniforge3/envs/secure-llm-gok/lib/python3.11/site-packages/libpyg.so\n",
      "  Reason: tried: '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file), '/Library/Frameworks/Python.framework/Versions/3.11/Python' (no such file)\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph saved to cache: ./cache/d822696b-23d3-4565-8a93-4ff532371ee8.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(x=[24], edge_index=[2, 154], edge_attr=[154], paragraph_features=[76], sentence_features=[0])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from confidentialgraph import ConfidentialSubgraphGenerator\n",
    "\n",
    "# Initialize the ConfidentialSubgraphGenerator\n",
    "generator = ConfidentialSubgraphGenerator(graph_file=\"./PacemakerInnovationsData/graph.pt\")\n",
    "# Generate the confidential subgraph\n",
    "generator.generate_subgraph(user_token=\"498f98ac-2bf6-4a16-a001-cbb19e7b82de\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Generating API endpoints and a quick streamlit UI\n",
    "\n",
    "Now we can finally combine it all into two endpoints:\n",
    "\n",
    "### Query Endpoint\n",
    "\n",
    "This endpoint will need a user token and a query and return an answer\n",
    "\n",
    "Under the hood it will generate a subgraph for that user, and then input the query and the subgraph into the `QuerryProcessor` and return an answer pretty much just combining the previous two steps.\n",
    "\n",
    "### Add knowledge\n",
    "\n",
    "This endpoint will allow you to add knowledge (filtered by topics that your user has access to)\n",
    "\n",
    "To run the app simply run:\n",
    "\n",
    "```bash\n",
    "docker build -t secure-llm-gok .\n",
    "docker run -p 8501:8501 -p 8000:8000 myapp\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secure-llm-gok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
